% $ biblatex auxiliary file $
% $ biblatex version 2.6 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated as
% required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup

\entry{Cour2008}{article}{}
  \name{author}{4}{}{%
    {{}%
     {Cour}{C.}%
     {Timothee}{T.}%
     {}{}%
     {}{}}%
    {{}%
     {Jordan}{J.}%
     {Chris}{C.}%
     {}{}%
     {}{}}%
    {{}%
     {Miltsakaki}{M.}%
     {Eleni}{E.}%
     {}{}%
     {}{}}%
    {{}%
     {Taskar}{T.}%
     {Ben}{B.}%
     {}{}%
     {}{}}%
  }
  \strng{namehash}{CT+1}
  \strng{fullhash}{CTJCMETB1}
  \field{sortinit}{C}
  \field{abstract}{%
  Compressive sensing (CS) is an emerging field that provides a frame- work for
  image recovery using sub-Nyquist sampling rates. The CS theory shows that a
  signal can be reconstructed from a small set of random projections, pro-
  vided that the signal is sparse in some basis, e.g., wavelets. In this paper,
  we describe a method to directly recover background subtracted images using
  CS and discuss its applications in some communication constrained
  multi-camera computer vision problems. We show how to apply the CS theory to
  recover ob- ject silhouettes (binary background subtracted images) when the
  objects of in- terest occupy a small portion of the camera view, i.e., when
  they are sparse in the spatial domain. We cast the background subtraction as
  a sparse approxima- tion problem and provide different solutions based on
  convex optimization and total variation. In our method, as opposed to
  learning the background, we learn and adapt a low dimensional compressed
  representation of it, which is sufficient to determine spatial innovations;
  object silhouettes are then estimated directly using the compressive samples
  without any auxiliary image reconstruction. We also discuss simultaneous
  appearance recovery of the objects using compressive measurements. In this
  case, we show that it may be necessary to reconstruct one auxiliary image. To
  demonstrate the performance of the proposed algorithm, we provide results on
  data captured using a compressive single-pixel camera. We also illustrate
  that our approach is suitable for image coding in communication constrained
  problems by using data captured bymultiple conventional cameras to provide 2D
  tracking and 3D shape reconstruction results with compressive mea-
  surements.%
  }
  \verb{doi}
  \verb 10.1007/978-3-540-88693-8
  \endverb
  \verb{eprint}
  \verb 1311.2901
  \endverb
  \field{isbn}{978-3-540-88692-1}
  \field{issn}{0302-9743}
  \field{number}{October}
  \field{pages}{158\bibrangedash 171}
  \field{title}{{Computer Vision – ECCV 2008}}
  \verb{url}
  \verb http://link.springer.com/10.1007/978-3-540-88693-8
  \endverb
  \field{volume}{5305}
  \verb{file}
  \verb :home/franky/Documents/Shared Documents/MLDM/Project/Papers/fulltext.pd
  \verb f:pdf
  \endverb
  \field{eprinttype}{arXiv}
  \field{year}{2008}
\endentry

\entry{Everingham2006}{article}{}
  \name{author}{3}{}{%
    {{}%
     {Everingham}{E.}%
     {M.~R.}{M.~R.}%
     {}{}%
     {}{}}%
    {{}%
     {Sivic}{S.}%
     {Josef}{J.}%
     {}{}%
     {}{}}%
    {{}%
     {Zisserman}{Z.}%
     {Andrew}{A.}%
     {}{}%
     {}{}}%
  }
  \keyw{Machine Vision}
  \strng{namehash}{EMRSJZA1}
  \strng{fullhash}{EMRSJZA1}
  \field{sortinit}{E}
  \field{abstract}{%
  We investigate the problem of automatically labelling appearances of
  characters in TV or film material. This is tremendously challenging due to
  the huge variation in imaged appearance of each character and the weakness
  and ambiguity of available annotation. However, we demonstrate that high
  precision can be achieved by combining multiple sources of information, both
  visual and textual. The principal novelties that we introduce are: (i)
  automatic generation of time stamped character annotation by aligning
  subtitles and transcripts; (ii) strengthening the supervisory information by
  identifying when characters are speaking; (iii) using complementary cues of
  face matching and clothing matching to propose common annotations for face
  tracks. Results are presented on episodes of the TV series "Buffy the Vampire
  Slayer".%
  }
  \verb{doi}
  \verb 10.5244/C.20.92
  \endverb
  \field{isbn}{1-901725-32-4}
  \field{pages}{92.1\bibrangedash 92.10}
  \field{title}{{Hello! My name is... Buffy'' -- Automatic Naming of Characters
  in TV Video}}
  \verb{url}
  \verb http://eprints.pascal-network.org/archive/00002192/{\%}5Cnhttp://www.bm
  \verb va.org/bmvc/2006/papers/340.html
  \endverb
  \verb{file}
  \verb :home/franky/Documents/Shared Documents/MLDM/Project/Papers/everingham0
  \verb 6a.pdf:pdf
  \endverb
  \field{journaltitle}{Proceedings of the British Machine Vision Conference
  2006}
  \field{year}{2006}
\endentry

\entry{K2009}{article}{}
  \name{author}{3}{}{%
    {{}%
     {K}{K}%
     {Pramod~Sankar}{P.~S.}%
     {}{}%
     {}{}}%
    {{}%
     {Jawahar}{J.}%
     {C~V}{C.~V.}%
     {}{}%
     {}{}}%
    {{}%
     {Zisserman}{Z.}%
     {Andrew}{A.}%
     {}{}%
     {}{}}%
  }
  \keyw{learning,machine vision,statistics {\&} optimisation}
  \strng{namehash}{KPSJCVZA1}
  \strng{fullhash}{KPSJCVZA1}
  \field{sortinit}{K}
  \field{abstract}{%
  A standard solution for aligning scripts to movies is to use dynamic time
  warping with the subtitles (Everingham et al., BMVC 2006). We investigate the
  problem of aligning scripts to TV video/movies in cases where subtitles are
  not available, e.g. in the case of silent films or for film passages which
  are non-verbal. To this end we identify a number of "modes of alignment" and
  train classifiers for each of these. The modes include visual features, such
  as locations and face recognition, and audio features such as speech. In each
  case the feature gives some alignment information, but is too noisy when used
  independently. We show that combining the different features into a single
  cost function and optimizing this using dynamic programming, leads to a
  performance superior to each of the individual features. The method is
  assessed on episodes from the situation comedy Seinfeld, and on Charlie
  Chaplin and Indian movies.%
  }
  \verb{doi}
  \verb 10.5244/C.23.121
  \endverb
  \field{isbn}{1-901725-39-1}
  \field{pages}{1\bibrangedash 11}
  \field{title}{{Subtitle-free Movie to Script Alignment}}
  \verb{url}
  \verb http://eprints.pascal-network.org/archive/00006560/
  \endverb
  \field{volume}{1}
  \verb{file}
  \verb :home/franky/Documents/Shared Documents/MLDM/Project/Papers/Paper273.pd
  \verb f:pdf
  \endverb
  \field{journaltitle}{Movie}
  \field{year}{2009}
\endentry

\entry{sabater_2017}{misc}{}
  \name{author}{1}{}{%
    {{}%
     {Sabater}{S.}%
     {Alberto}{A.}%
     {}{}%
     {}{}}%
  }
  \list{publisher}{1}{%
    {Machine Learnings}%
  }
  \strng{namehash}{SA1}
  \strng{fullhash}{SA1}
  \field{sortinit}{S}
  \field{title}{Automatic Subtitle Synchronization – Machine Learnings}
  \verb{url}
  \verb https://machinelearnings.co/automatic-subtitle-synchronization-e188a927
  \verb 5617
  \endverb
  \field{journaltitle}{Machine Learnings}
  \field{year}{2017}
  \warn{\item Invalid format of field 'month'}
\endentry

\lossort
\endlossort

\endinput
